。##### flink keyby算子介绍
keyby要求传入一个key作为条件，按照不同的key的值将数据写入不同的分组发送到下游不同的operator。keyby会导致shuffle过程，有额外的序列化和反序列化以及IO开销，会影响吞吐量。对于状态后端也会有很大的压力。对于key的值有一定的要求，如果粒度太粗容易有数据倾斜，如果粒度太细，又会有效率问题。


##### k8s部署与yarn部署的区别
k8s有更好的资源与网络隔离性、安全性，弹性扩容，适合多租户。
k8s有更好的生态系统。
但是k8s的学习成本比较高。


##### 什么情况下出些数据倾斜，如何解决
通过flink web ui我们看一观察到任务的反压状态。一般来讲出现反压不一定是数据倾斜造成的，但是出现数据倾斜一定会造成任务的反压。出现数据倾斜一般都是由于代码中使用了keyby算子，而数据中的某些key存在热点导致的。
通常增加并行度解决不了倾斜问题，倾斜往往导致某些节点出现OOM，导致内存溢出，任务失败重启。
一般的解决思路是避免热点key出现，如果有热点key尽量在业务中单独处理；
或者采用给key加盐的方式，打乱数据分布规律，采用两阶段的keyby彻底解决倾斜问题。


##### watermark机制，延迟数据如何处理
watermark必须依赖于窗口，所以讲一下窗口先。
Window是处理无界数据流的关键，它会将数据流拆分为一个个的有限长度的buckets，我们的计算需要在这个buckets中进行。每一个window都有一个起始时间和结束时间，这个时间与数据无关，它采用系统时钟。
当数据进来处理是，会使用数据的时间(event_time)对比当前的窗口范围，如果在这个范围就等待，直到有超出窗口的数据出现，触发窗口的计算。
此时我们就会发现问题，现实中的数据不会这么严格按照顺序，反而是“乱序”进来的。比如说在12：00-12：01这个窗口，可能出现11：40的数据（延迟），一条12：01：03的数据可能在12：02出现（“乱序”）。那怎么解决这些问题呢？
对于乱序问题，是借助watermark来保证的。watermark被称为水位线，就是一个时间线。加入我们定义watermark大小为10s，数据当前时间为12:01:09，就可以用二者相减，得到的时间是：12:00:59，那么它任然属于12：00-12：01这个窗口。watermark是跟随数据的时间确定的，此时窗口触发计算的时机就完全由watermark来控制了，当一条数据watermark超过当前窗口的结束时间，那么就会立即触发计算操作（先不考虑延迟数据，即使是有延迟处理逻辑，这里也会计算一次），当前窗口结束。
可能你会想问，如果有条数据时间是11:30:23，这个时候到来怎么办？实际上它根本进不来这个窗口，flink默认会将超出watermark管控的数据丢掉。
我们会发现，有了watermark实际上也不能完全处理乱序数据呀（乱序的极致就是延迟），你提前定义了一个watermark的size，实际的数据并不会按你定义的来呀。确实是这样，flink无法一直等待数据进来，这样的话永远也不知道何时才能计算。这时有个场景，数据延迟没有赶得上计算，flink默认把它丢了，那么我想把它保存下来怎么办，或者说这些延迟的数据我还是要加进去窗口算，这怎么办？
对于要保存延迟的数据，可以使用sideoutput功能，迟到的数据你可以保存到任意一个sink的地址。
如果要对延迟的数据重新触发窗口计算，可以使用allowlateness功能，开启后也需要传入一个时间大小，当当前窗口触发计算后，其状态需要保留（保留的时间是你传入的时间范围），当在这个时间内有新的属于这个窗口的数据进来（触发计算的时间由传入的时间决定，不再看数据的时间了），再次触发窗口计算。需要注意，这样做会对状态后端产生比较大的压力，时间不要太长。


##### 消费kafka发现watermark无法触发，分析下原因
flink watermark水印是处理乱序数据的，。
watermark需要实时输入的数据才能触发，换句话说当一个operator的subtask一直没有新数据进来，那么这个窗口就无法结束，虽然其他的subtask满足了条件，但是这里是木桶原理，只要有一个结束不了，那整个任务就走不下去。
这种情况出现的原因可能是某些partition由于业务逻辑或其他原因导致没有数据；
或者这个topic新增了一个partition，但是数据量不平衡等导致。

##### 对于算子状态有了解吗，ontimer知道吗，怎么使用？
flink中的算子是有状态的，根据算子不同分为两类：operator state和keyed state。其中keyed state只能跟keyby算子运算。

状态在flink进行cp时存在状态后端，用的时候要读入内存，序列化为java的对象。
对于operator state目前提供了三中的数据结构存放状态数据：
列表状态： List State
联合列表状态： Union list State
广播状态： Broadcast State

对于keyed state目前提供了以下数据结构存放状态数据：
Value State[T]
List State[T]
Map State[T]
Reducing State[T]
AggregatingState[I, O]

状态变量需要在open()函数里初始化，通过getRuntimeContext()注册StateDescriptor。

ontimer就是一个触发器，当满足条件后执行的动作。

以下是一个实际的例子：
```java
public class StateTest {
    public static void main(String[] args) throws Exception {
        /*
        * 数据有3个字段，id，时间戳，当前液位，eg:【001,1646274620,10】。
        * 要求检测液位的变化，当前液位与上一次的液位差超过40后，立即触发报警
        * 涉及到state，ontimer等知识点
        * */
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        // nc -lk 9999
        DataStreamSource<String> stream = env.socketTextStream("172.16.7.63", 9999);

        SingleOutputStreamOperator<WaterSensor> map = stream.map(
                line -> {
                    String[] arr = line.split(",");
                    return new WaterSensor(arr[0].trim(), Long.parseLong(arr[1].trim()), Integer.parseInt(arr[2].trim()));
                }
        );

        SingleOutputStreamOperator<WaterSensor> markDS = map.assignTimestampsAndWatermarks(
                WatermarkStrategy.<WaterSensor>forBoundedOutOfOrderness(Duration.ofSeconds(10))
                        .withTimestampAssigner((sensor, timestamp) -> sensor.checkTime * 1000)
        );

        SingleOutputStreamOperator<Object> laterWater = markDS.keyBy(sensor -> sensor.id).process(new KeyedProcessFunction<String, WaterSensor, Object>() {
            // 保存的历史的状态，必须在open中初始化，否则报错
            private ValueState<Integer> laterWaterLevel;
            private ValueState<Integer> realGap;

            @Override
            public void open(Configuration parameters) throws Exception {
                laterWaterLevel = getRuntimeContext().getState(new ValueStateDescriptor<Integer>("laterWater", Integer.class));
                realGap = getRuntimeContext().getState(new ValueStateDescriptor<Integer>("realGap", Integer.class));
            }

            @Override
            public void onTimer(long timestamp, OnTimerContext ctx, Collector<Object> out) throws Exception {
                // 触发条件在processElement中
                out.collect("水位超过40cm，请立即处理！当前液位差是：" + realGap.value());
            }

            @Override
            public void processElement(WaterSensor waterSensor, Context context, Collector<Object> collector) throws Exception {
                // 如果当前时间的水位减去上次的水位超过40，则触发报警计算ontimer逻辑
                if (laterWaterLevel.value() != null) {
                    if (Math.abs(waterSensor.waterLevel - laterWaterLevel.value()) > 40) {
                        // 这里处理ontimer的触发时机，返回一个long类型的时间戳，如果比当前时间小，则立即执行，也可以加一个整型数据，延迟触发也可以
                        context.timerService().registerProcessingTimeTimer(context.timerService().currentProcessingTime());
                    }
                    realGap.update(Math.abs(waterSensor.waterLevel - laterWaterLevel.value()));
                } else {
                    realGap.update(0);
                }

                // 更新状态
                laterWaterLevel.update(waterSensor.waterLevel);
            }
        });
        laterWater.print();
        env.execute();
    }
}

class WaterSensor {
    String id;
    Long checkTime;
    Integer waterLevel;

    public WaterSensor() {
    }

    public WaterSensor(String id, Long checkTime, Integer waterLevel) {
        this.id = id;
        this.checkTime = checkTime;
        this.waterLevel = waterLevel;
    }
}
```
注意trigger与timer的区别。trigger用在window窗口中，作为出发窗口计算存在的。


##### checkpoint机制的流程（触发，传播，完成），2PC，分布式快照
checkpoint流程是由jobManager中的Checkpoint Coordinator发起并协调的。
1）当coordinator确定当前需要进行checkpoint操作，就会向当前job中的所有source算子trigger Checkpoint，在数据中注入barrier。
2）source算子向其所有的下游广播发送barrier，这个barrier就是实现分布式快照的核心。下游的算子只有在接收到所有Input的barrier后才执行它对应的checkpoint操作，将其状态信息异步写入状态后端中，状态后端在接收到信息后会将ack确认消息发送给coordinator。
3）下游的sink节点在收集全部的上游input的barrier后，每个sink节点会开启事务，将数据写入外部系统后，将状态信息异步写入状态后端（2PC, prepare commit）。
4）当checkpoint coordinator接收到所有task的状态，且sink端的所有节点的事务全部成功时，此刻认为此次checkpoint全部完成（如果失败，则任务失败退回到前一个checkpoint成功的点），其向sink端发送确认消息，sink端收到后会将事务提交（2PC, commited）。同时coordinator发出指令，将状态后端当前这次的状态持久化一份到文件系统(hdfs)。

##### checkpoint与state、statebackend的关系
状态是算子层面的，实现了特定接口的算子本身需要保存某一时刻的状态（变量的值），这个状态需要在下一条数据来时读取利用。也就是说有状态的算子每次处理数据都需要读取之前的状态，读完后可能会更新这个状态。状态一般是保存在state backend(rocks DB)，一般会有一个缓存，直接读内存，读不到再去跟rocksDB交互。

流式任务运行时可能出现异常导致失败，需要定一段时间就保存一次当前各个算子的状态，方便失败时重启任务，这个过程就是checkpoint。他就是把任务做一个快照，保存其在某一时刻的样子。

当触发checkpoint时，状态信息会写入状态后端。状态后端可以是文件、内存或者RocksDB，需要有较好的读写能力，因为运行时需要频繁的读写。

实际上checkpoint结束后，还需要将快照的状态再复制一份到磁盘做持久化。

##### checkpoint慢如何定位问题
1）rocksDB性能问题。
2）状态很大，同步需要时间。
3）barrier对齐情况下，部分task数据倾斜导致不能及时完成，其他task一直等待

##### exactly once/ At least once对checkpoint的影响
barrier非对齐模式下无法实现精准一次消费。


##### checkpoint与savepoint的区别
savepoint是由用户手动触发，一般用户集群或升级；
checkpoint是程序自动完成的，用于作业在运行中异常导致的失败，使任务恢复使用的。‘

##### 关于operator chain的理解
flink的一些算子可以链接在一起，放在同一个task执行，同一个task里面的各个operator之间数据的调用变为函数级的调用，减少数据的传输，是flink的一种优化方式。比如说source->map->filter就可以串联到一个chain中。底层涉及到flink graph的生成和优化。

##### sql执行流程， catalog的理解
flink sql 底层基于开源项目calcite完成的，分为以下几个步骤？
* 1）Parse语法解析。使用Calcite把用户提交的Sql语句转换为抽象语法树，对应于SqlNode节点
* 2）Validate语法校验。使用元数据进行验证，例如表、函数是否存在；where ,group by 等语句是否合法
* 3）Optimize查询计划优化。分为两部分，1）首先将SqlNode语法树转换为关系表达式RelNode构成逻辑树；2）食用优化器基于规则进行等价变化，如谓词下推、列裁剪等，生成最有的查询计划
* 4）讲逻辑计划翻译成物理执行计划，生成可执行代码，提交运行


catalog提供元数据的信息，例如数据库、表、分区、视图、函数等信息。
数据处理最关键的方面之一就是管理元数据。元数据可以是临时的，例如临时表，或者通过TableEnvironment注册的UDF。元数据也可以是持久的，如Hive Metastore中的元数据。Catalog提供统一的接口API，用来管理元数据，并借助Table API和SQL查询语句访问。
Flink中有一个Catalog的interface，提供了几组API，包括Database层、Table层、View层、Partition层、Function层，每一层分别对应一些列不同的功能。
Calalog是可以扩展的，通过实现Calalog接口来自定义。除此之外，还需要为其实现CalalogFactory接口。


##### flink的序列化方式
flink没有使用java的序列化方式，反而自己实现了一种序列化方式，原因在于java的序列化方式对象存储很稀疏，需要保存class的header，填充的对其数据等，会占用空间降低效率。
flink基于TypeInformation描述类型信息实现序列化。flink为多种数据定义好了序列化的方式，比如PojoTypeInfo, ValueTypeInfo等。


##### flink链路延时监控
当我们需要观察job任务流程中哪一个算子延迟程度高，哪里费时，或者做任务的全链路监控，需要了解算子级别的延迟信息。
flink提供了开箱即用的功能，通过参数：`metrics.latency.interval`参数，然后观察TaskmanagerJobMetricGroup/operator_id/operator_subtask_index/latency这个面板就可以了。
这个时间间隔宜大不宜小，一般配置30s左右。这是因为延迟的监控频率本身不需要太频繁；二是它本身也会有一定的性能损耗。

用户可以自己定义metrics，实现个性化的监控指标。

##### kafka为什么去掉了zookeeper，zk有哪些缺点？
在之前的版本中，zk可以说是kafka的核心，没有zk，kafka集群甚至启动不了。
kafka集群启动时，首选需要启动zk集群，然后再启动kafka。启动时，kafka进程需要往zk集群注册一些信息，比如说brokerId。集群启动后，zk还为kafka提供了可靠的元数据存储，比如Topic/Partition的元数据，Borker数据、ACL信息等。
zk还担任着集群的领导者。当kafka集群需要扩容、分区迁移等操作，都需要zk的参与。

但是使用zk过程中发现了两个主要问题：
1）须同时运维zk和kafka，增加了运维的复杂度和成本；
2）zk会限制kafka集群的规模（可承载的分区数）。kafka依赖一个单点的Controller节点（kafka集群中的一个Broker节点经过选举称为controller角色）管理大多数与zk的读写和运维操作，并在其本地缓存zk上的所有元数据。当分区数增加，zk需要管理的元数据也越来越多，从而加大zk的负载，导致延迟或丢失。

2.8版本后的kafka如何在去除zk的前提下解决这戏问题的？
新版kafka元数据保存在自身。之前的Controller被换为Quorum Controller，Quorum里面有多个Controller，它们都会通过Raft协议备份最新的元数据。

##### kafka消费者其中一个挂了，会发生什么？重平衡了解吗
kafka的一个消费者组里面可以有多个消费者实例，通常情况下我们设置消费者数量等于topic的分区数，以最大化利用资源。如果设置的消费者数量大于分区数，则多出的那部分消费者是闲置状态；如果少于分区数，一个消费者可能处理多个分区的数据。
kafka有一个重平衡机制，其目标是让一个消费者组下所有的消费者合理分配订阅分区数据，有3种场景会触发这个重平衡：
1）消费者组内的消费者数量发生变化（程序异常情况下会导致部分消费者退出，心跳超时误判）
2）订阅的topic数量发生变化，我们可以使用正则，同时消费多个主题的数据
3）topic分区数发生变化

重平衡这个功能本意是好的，但是实际使用会发现严重的问题：
1）Reblence过程中消费者组下的所有消费者全部无法正常消费数据，都是等待状态
2）所有的消费者都会参加Reblence过程，即使某些消费者已经是合理的了，也需要再次打散
3）Reblence过程重建TCP连接，非常消耗资源，耗时。且下游的消费者数量越多，这个过程越漫长。

重分配是一个无法解决的问题，只能尽量避免。
对于分区数量的变化，程序端无法预防，只能从消费者组成员变化入手优化。而且一般只能对由于心跳超时导致的误判这种做处理，加大超时时间，或者降低心跳发送的频率。

##### 数仓设计中，缓慢变化维度表怎么处理？拉链表
我们在使用数仓的维度表时会遇到这样一种情况，维度表比较大（用户表，几千万的数据量），表中的信息会不定时更新（邮箱、地址等），更新的比例和频率也都不高。业务中需要查看某一个时间点的历史快照信息。一般这种情况就是缓慢变化维问题。
解决这个问题可以有以下集中方式：
1）只保留最新的一份数据，比如sqoop抽取最新数据
2）每天分区保留一份全量数据
3）拉链表

不难发现，方式1虽然简单，但是历史快照无法保留，特定业务场景无法解决。方式2可以保留历史快照，但是每天一份全量数据，遇到大的维度表会对资源造成浪费。当前只有拉链表可以很好的满足这种需求（并非完美）。

拉链表设计的核心就是需要2个字段：start_date/end_date，这两个字段标识了当前一条数据的有效期限，通过where的筛选作用，选出历史某一时期的快照。

在hive中实现拉链表，我们先需要筛选出维度表中当前一天的增量更新数据，然后去跟当前状态的拉链表JOIN或者UNION，得到最新的拉链表，这个拉链表是不分区的。

##### YARN 架构设计，组件作用
YARN是Hadoop2.0时代出现的产物，总体上是master/slave架构，其包括的主要组件是：ResourceManager/NodeManager/ApplicationMaster/Container。
RM：全局的资源管理器，集群只有一个（高可用下有多个，只有一个是active）。负责系统的资源管理和分配，包括客户端请求、启动/监控App master，在其失败时重启、监控NM、资源的调度和分配
NM：集群有多个，负责每个节点上的资源管理和使用。它需要处理来自RM的命令，处理APP master的指令，上报状态。
AM：管理每个应用程序的实例，向RM申请资源，要求NM启动任务。负责程序的运行监控和资源使用。
Container：YARn分配资源的最小单位，一个container包括内存和CPU。

##### YARN 当RM挂掉后任务是否正常执行？
RM如果是高可用，则切换到其他RM节点，任务正常执行；
RM如果是非高可用，新任务无法正常提交执行；
    已经执行的任务，如果AM没有发生失败或者重启，也可以正常执行，但是任务最后会向RM注册主动释放资源，这里可能会有问题；
    已经执行的任务，如果一些container失败，则由NM负责重启等任务，应该不会受影响；
    已经执行的任务，如果某些NM挂掉了，需要协调其他NM，此时RM无法使用也会导致任务失败；
    
    
##### ES的架构，部署？
es是一个分布式的搜索和分析引擎，可用于全文检索、结构化检索和分析。其节点有不同的类型：
* Master-eligibal node：指具有资格被选举为Master的节点，一般配置奇数个。真正的Master节点在这些nodes中选举产生，其负责集群节点的发现和元数据管理。Master节点会周期性ping其他节点，确定节点是否存活以及shard在每个data node节点的分布，不断地更新和维护元数据。
* Data node：存储数据的节点，数据以shard的形式保存在data node中。定时性地向master发送心跳，感知master是否存活，当其中一个节点认为master挂了则走选举流程。
* Ingest node、Transform node、Machine learning node等等，这些不太重要。

向es中添加记录、删除记录等操作并不需要经过master，因此单个master节点不会影响集群的性能。es每一个节点都维护了一个Routing Table，Routing Tbale记录了Index对应的Primary Shard和Replica Shard分布在那些地方（node）。只有Master节点可以更新Routing Table，在更新后分发给其他的节点。

##### ES字段类型修改方式
首先，已经建好的mapping，其字段类型是绝对无法修改的，只能新增字段，不能删除或者修改类型。
为了解决这个问题，有以下几个方式使用：
1）新增一个字段，将旧字段废弃；
2）新建mapping和索引，将旧数据reindex到新索引。

##### ES分片和副本的作用
* 分片：分片是创建索引的时候就确定的，后续无法被修改。一个分片底层就是一个完整的Lucene索引，它可以提供完整的搜索能力。分片出现的原因在于，当一个索引的数据量比较大时，内存的限制、磁盘的能力会导致无法跟上客户端的请求。将一个索引切分成不同的分片，每个分片放在不同的节点上，当我们使用时分片对用户透明，底层将请求发送到相关的分片去处理，这样可以提高吞吐量，提高响应速度。
* 副本：一个索引可以有多个分片，每一个分片可以配置0到多个副本。副本是分片数据的备份，数据是写入主分片，副本去同步最新的主分片数据。副本出现解决2个主要问题，一是分布式环境下数据安全问题，副本可以在主分片丢失时作为主分片使用；二是提高吞吐量，ES的客户端在搜索时可以不请求主分片，直接从副本搜索，在并发访问时很有效。

当数据在写入的时候，有一个**路由**的过程，默认根据数据的_id取哈希值，然后分发到不同的分片中。这也是分片数量不能被修改的原因，因为一旦修改，之前的数据就不知道它被路由到哪个分片了。

##### ES search的过程
搜索分两个阶段：
* Query：首先客户端请求协调节点，将查询请求发送到索引的每一个分片（主分片或副本都有可能，有负载均衡机制）。没一个分片在本分片上执行搜索并构建一个from+size的优先队列。查询完成后返回给协调节点一个from+size大小的数据队列，包含了文档id和排序值。
* Fetch：协调节点收到后对所有的分片做全局的排序，并过滤掉删除的数据（标记删除），将需要返回的文档分别请求各分片，要求其返回真实的数据。协调节点拿到数据后返回给客户端。
由于在query阶段文档的排序都是在各自的分片上进行的，所以可能结果的顺序不是特别精确（文档太少，其相关性计算受影响），只要数据量大了就不会看出来了。

##### ES index 写入过程
1）客户端请求协调节点，默认使用文档ID作为路由算法的输入，以确定将数据写到那个索引分片。
2）当分片收到协调节点的请求时，将数据先写进了内存缓冲区，定时1s清空这个缓存，将数据写入到文件缓冲，这便是refresh阶段。refresh完成后，数据在文件缓冲中行成段这个概念，一旦行成段，那段中的数据就是搜索可见的。
3）文件缓冲中的数据默认30s或者超过512M之后会刷新进磁盘，这个过程是flush。
4）文件缓冲中的数据需要被刷新写入磁盘才能确保安全，但是在节点重启等情况下文件缓冲中的数据会丢失。为了解决这个问题，es索引的数据每次进行添加、更新、删除操作时，需要将这个操作保存到translog文件中，当段被成功刷新进磁盘，这个translog中的数据被删除。一旦节点重启，缓冲丢失，它将通过检查点文件从translog文件恢复数据。

##### ES的refresh与flush的区别
默认情况下ES每隔一秒钟执行一次refresh，用来将内存缓冲区的数据写入新的segment，使得内容搜索可见，但是此时数据还未写入磁盘，有丢失的可能。

ES会在translog中记录一段时间内数据的变化，随着时间延长，这个文件可能很大，需要将其刷入磁盘，并删除旧的translog，这个过程称为flush。

##### 反/序列化
序列化：将对象转为字节流
反序列化：将字节流转换为对象
通过序列化可以将对象的字节序列持久化，保存在内存、磁盘或数据库中等。可以在网络上传送对象的字节序列，经反序列化实现远程调用。

**序列化不会关注静态变量。**

serialVersionUID是jav为每个需要序列化的类产生的版本标识，用来确保在反序列化时，发送发发送的和接收方接受的是兼容的数据。如果不一致会抛出异常。

对象中有些数据不希望被序列化，那么可以使用transient关键字修饰成员，这样可以在进行序列化时忽略这个数据。

如果想自定义序列化的逻辑，可以通过实现Serializable接口，实现serialize和deserialize来自定义逻辑。

java序列化的缺陷：
1）无法跨平台。只有Java采用这种协议，相比之下fastJson, jackson, thrift等第三方工具使用场景更多。
2）性能较差。java使用objectOutputSteram来实现对象转二进制编码，编码后的数组很大，影响效率，而且序列化的速度也比较慢。
3）容易被攻击。在反序列化字节流的过程中，readObject()几乎可以执行任意代码。
4）编程限制。想要自定义一定需要实现Serializable接口，需关注serialVersionUID的变化。

##### 泛型


##### 容器
* 容器与数组。
   在存储长度上，数组是固定的，容器长度是可变的；在支持的数据类型上，数组可以存储基础类型或者引用数据类型，而容器只能存引用数据类型。
* Comparable与Comparator。这两个为的是解决对象的排序问题。如果一个类实现了Comparable接口，重写compareTo方法，则该类的对象具有自定义的排序属性。如果一个类无法被修改，我们可以定义一个Comparator比较器，通过实现compare方法来实现对象的排序。
* 容器的fail-fast机制。对于容器类的对象，有时候需要在遍历的同时删除一些元素，但是容器内部有一个modCount的Int值，当进行迭代、遍历或序列化操作时，操作前后要比较前后modCount值是否改变，如果改变，就会报：ConcurrentModificationException异常。如果确实需要一边遍历一边删除，可以考虑在iteator遍历的时候，再去remove元素。这样可以确保删除当前迭代的元素，但是每次迭代只能删除1个元素。
###### 关于List
List是一个接口，表示有序的队列。其常见的实现类包括ArrayList，LinkedList，Vector和Stack。
* 关于ArrayList和LinkedList。
ArrayList底层基于数组实现，其初始数组大小是10，如果放不下会扩容，但是扩容是有上限的，也就是说ArrayList有容量上限。其随机访问速度很快，但是相对的随即插入更新速度较慢（每次随机插入都会导致底层数组的移动，数据越靠前，代价就越大）。线程不安全。
LinkedList底层基于双线链表实现，其容量理论上是无限的。其随机插入、随机访问速度快，相对的随机访问速度慢（需要靠前后向的指针依次往前或往后移动获取数据）。线程不安全。
* Vector和Stack。
上面的两种List实现都不是线程安全的，为了解决线程安全问题，又出现了Vector和Stack。
Vector与ArratList类似，但是其内部方法主要是synochronized的，确保了线程安全。
Stack也是同步的容器，继承自Vector，主要是模拟了栈的功能（先进后出）

###### 关于Map
Map家族主要有以下大类：
AbstractMap：一个抽象类，核心的API，拥有大量的抽象方法。
SortedMap：需要对key排序的Map需要实现，通过Comparator实现对象的排序(TreeMap)。
Hashtable：它是一个线程安全的Map实现类，只是由于大量使用synchronized关键字导致效率很低，目前一般使用concurrent包代替。

Map是一个保存键值对数据的接口，内部不能包含重复的key，每个key只能映射一个value。

* HashMap：以散列的方式存储键值对，内部使用数组+链表+红黑树保存数据。允许键和值出现空值，有两个影响其性能的参数：①初始容量，初始容量取得合理可以避免频繁的扩容②负载因子，决定在自动扩容前允许的最大饱和度，默认0.75。其线程不安全。
由于HashMap初始底层只有16个位置，其存储的数据量是有限的，所以想ArrayList一样，它也需要扩容。扩容的条件是根据负载因子来计算，如果当前底层数组容量超出（总容量*负载因子）时，则触发一次扩容。同时，当数据被put进来的时候，首先根据其hash值，采用散列算法，得到其分桶的位置，如果该位置没有其他数据，则被插入；如果有其他数据，需要借助equals方法，具体来说：数组的每个位置初始存的是一个单向的链表，当新的key进来时，依次遍历这个链表，先判断equals值是否相等，如果相等，则替换旧的值，如果不相等，则继续往后遍历。到最后还没有相等的，就在链表的最后插入。随着数据越来越多，链表的长度会变得特别长，这样不管是插入还是查询，都会带来不小的性能损耗。为了解决这个问题，HashMap设定了：如果当前链表长度大于8，且底层书长度大于64，则将该位置的链表转为红黑树（如果数组长度小于64，则触发扩容），利用红黑树的特性提升效率。如果某个数据被删除，可能将红黑树再次转为链表。

* LinkedHashMap：它是hashMap的子类，不同点在于，它维护了一个双向链表，保证元素在迭代遍历时的有序性。其允许空key或空value，线程不安全，迭代有序等特性。
* TreeMap：底层基于红黑树存储数据，其key需要经过排序，默认根据key的自然顺序排，也可自定义Comparator传入构造器或者对象实现Comparable自定义排序逻辑。他也是线程不安全的。

###### 关于Set
参考Set来就好了。

##### 多线程
**安全性问题**
使用多线程会有安全性问题，原因通常表现在3方面：
* 可见性：我们程序内的计算都是用CPU完成的，假设两个线程同时操作共享变量，初始值为0，我们假设线程 A 和线程 B 同时开始执行，那么第一次都会将 count=0 读到各自的 CPU 缓存里，执行完 count+=1 之后，各自 CPU 缓存里的值都是 1，同时写入内存后，我们会发现内存中是 1，而不是我们期望的 2。通过volatile关键字可以使CPU寄存器中的变量改变对其他CPU可见。
* 原子性：使用高级编程语言往往一条指令需要多个CPU指令完成，比如说count+=1，要完成它需要3条CPU指令，首先将变量加载进CPU，然后在寄存器+1，最后将数据写回内存。但是多线程下，线程可以在任意一条CPU完成后切换，最终可能导致计算结果不对。
* 顺序性：java虚拟机会对指令做优化重新排序，比如初始化一个类的实例时，理论上是先开辟内存空间，然后初始化实例，最后将地址赋给变量的引用。重排后可能顺序就是开辟空间->赋给内存地址值->初始化对象。造成的结果是，多线程情况下，实例未初始化就使用的问题。
volatile关键字可以解决指令重排优化和CPU缓存数据的可见性问题；synochronized或Lock保证操作的原子性。

**线程的状态**
新建：尚未调用start方法时，线程处于此状态。
就绪：已经调用了start方法，但是他可能已经处于running阶段；也可能处于等待资源调度的阶段，还没有正式开始执行，也就是ready阶段。
等待：调用wait主动释放锁，需要外界唤醒。
阻塞：被动的停止，竞争到锁资源才能执行。
定时等待：sleep状态。此时它并没有释放同步锁，其他线程不能访问同步资源。
终止：线程执行完，或者异常退出。

**切换状态的方法**
yield：从running切换到runnable状态，主动释放执行权，只有与当前线程相同或更高优先级的线程才可能获得执行权。
sleep：切换到waiting状态。
join：本线程阻塞，转而执行其他线程。其他线程执行完才切换到本线程。

**创建线程的方法**
1）继承Thread类，重写run()方法；
2）实现Runnable接口，重写run()方法；
3）实现Callable接口，重写call()方法，通过FutureTask包装，借助Thread类提交
4）线程池

**线程礼让**
yield
**线程终止**
不要使用stop()方法，有缺陷，可能导致无法回收锁资源；
可以使用interrupt()方法使线程中断；

**守护线程**
依托于用户线程，用户线程结束，它也被迫结束。比如说java的垃圾回收器。

**J.U.C**
java.util.concurrent包的缩写，包含了java并发编程最核心的类。
包括：AtomicInteger, ReentranLock, ConcurrentHashMap, ThreadpoolExecutor等。

**synchronized**
保证同一时刻，只有一个线程可以操作某个方法或代码块；
可以用来：
1）同步实例方法（锁是this）
2）同步静态方法（锁是类.class）
3）同步代码块（锁是()中自己指定的）

需要注意：静态的字段或属性属于类，只有类级别的锁才能保护；非静态属性属于对象，对象级别的锁就可以保护。

**volatile**
它是一个轻量级的synchronized，其具有：变量在线程之间的可见性，以及指令重排功能，但是不保证指令的原子性。
它的开销比synchronized小，如果变量值的修改不依赖于当前值时，可以考虑使用。

**CAS**
我们在使用synchronized或lock是，采用的是互斥同步原理，是一种悲观的保护机制。实际的多线程场景中，很多情况下是不会发生冲突或者很少发生冲突的，这种情况下使用悲观锁就会影响效率。为了解决这个问题，可以采用乐观锁。即平常情况下大家共同操作变量，只有在发生冲突时，采取保护机制。我们是借助cas机制来实现的，这个机制不是java提供的，而是依赖于操作系统的。我们常见的AtomicLong/AtomicInteger就是基于这个机制实现的。

**ThreadLocal**
存储属于当前线程本地副本的工具类。有些情况下，有些数据可以给每个线程一份，其他线程无法使用，这样保证并发场景下的数据安全。

**互斥与同步**
* 互斥：同一时刻只允许一个线程访问共享资源；
* 同步：线程之间如何通讯。

**锁的分类**
* 公平锁与非公平锁：公平锁线程竞争锁按照先后顺序，保证公平；非公平锁按照线程优先级，优先级高的获取锁资源概率大。非公平锁效率更高，但是可能发生饥饿现象。
* 可重入锁：在获取外部锁的情况下，内部锁不需要再次竞争（保证是同一把锁）。

**lock与condition**
与synchronized类似，lock也是用来解决线程的互斥同步问题，解决安全性问题。它与synchronized的区别在于：
1）它支持公平/非公平锁，而sync只支持公平锁；
2）sync可能出现死锁的现象，而Lock可以采用外置的手段打破锁未释放导致的线程阻塞的僵死状态，避免死锁。

**ReentranLock类**
它是java Lock 的一个具体实现类。它有Lock, unLock, tryLock等方法。

**线程池**
在并发访问量高，线程频繁创建销毁的场景下，使用线程池可以大大提高效率。

其核心的类是：ThreadPoolExecutor, Executors。

* ThreadPoolExecutor：线程池执行时的核心对象，一般我们不直接创建它的直接实例，而是通过Executor这个类创建出各种功能的线程池服务类，再强转为这个类的实例。它可以通过submit(有返回值)或者execute(无返回值)去启动线程任务执行。其核心的参数：
* * corePoolSize：核心线程数量。当有新任务进来时，如果当前线程数小于该值，则启动新线程，即使其他线程是空闲的。
* * maximumPoolSize：线程池最多的线程数量，
* * keepAliveTime：核心线程之外的其他线程，如果没有分配任务，存活的时间。

* Executors：通过它可以创建出各种功能的线程池。比如说newFixedThreadPool,
newCachedThreadPool, newScheduleThreadPool等。


##### java类加载过程
java类加载过程主要分为以下几个重要的步骤：
1）加载类：就是讲二进制字节流的class文件加载进内存，读进方法区，在堆中形成Class对象，可以操作这个类。
2）验证：验证class文件格式是否合规，文件内容语法语义是否正确等。
3）准备：将静态的变量初始化为规定的值。它发生在用户代码执行前。
4）初始化：执行用户的代码，如构造函数、构造函数等。


此外当类被主动使用后，一般还有使用阶段和卸载阶段。

类加载阶段不一定是用户调用才出发，虚拟机有时会提前加载类。


##### GC调优


##### 反射的理解



##### JVM相关


##### 垃圾回收机制









