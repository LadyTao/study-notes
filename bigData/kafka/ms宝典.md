[TOC]

#### 为什么要用kafka
> 1. 缓冲与削峰。利用kafka作为中间件，将突发的流量数据暂存在这里，下游的流程可以慢慢处理；
> 2. 解耦与扩展。将操作请求写到kafka，模块之间解除联系；
> 3. 冗余。一个主题多个消费者订阅，彼此独立；
> 4. 异步通信。

#### kafka消费过的数据如何再消费
> 每个消费组会拥有一个offset值记录当前消费的message位置，通过接口更改这个值就可以重复消费数据。

#### kafka的数据是放在磁盘上还是内存上，为何速度这么快
> 磁盘。
> 1）顺序写入。随机写会频繁的寻址->写入，这样速度会很慢。顺序写速度更快。
> 2）数据分段。每个partition分为许多的段，每个段呗放在单独的文件，且文件名以该段最小的offset命名，通过二分查找快速定位。
> 3）文件索引。在单个文件中定位message时同样可能比较慢，因为需要顺序扫描。kafka为分段后的文件建立索引，行成.index文件，快速定位单个文件中的message位置。

#### kafka数据如何保障不丢失
> 1) 生产者。生产者发送数据时，有一个ack的反馈功能(0->不许等待broker，持续发送;1->leader接收成功后再发送;-1->全部的副本也接收成功后再发送)，确保消息可以正常写入不丢失。此外在异步发送模式下，prducer端有一个buffer，如果数据满了数据还没发送出去，可以一直阻塞程序，数据就不会一直生产，保证数据不丢失。
> 2) 消费者。消费者的offset信息目前都保存在topic中，每次消费数据不会立即把offset的位置提交到kafka，导致宕机或异常情况下数据被重复消费，但不会丢失。但是不同的任务不要用同一个groupid，这样会有问题。
> 3) broker端。partition都会有副本，数据写入leader后，follower会跟leader同步新数据，多个副本保证安全。

#### 采集数据为什么选择kafka
> kafka延迟低，数据安全，吞吐量高，逐渐成为大数据的标配。与此相对的有Flume，它与Hadoop捆绑在一起，也比较好用，但是kafka的使用场景更广。

#### kafka重启是否会导致数据丢失
> 数据存在磁盘，一般不会丢数据。

#### 为什么kafka不支持读写分离
> 我们使用kafka过程中，读和写都是通过操作leader副本进行的，也就是所谓的`主读主写`的消费模型，这与es不一样，es可以直接读副本提升吞吐量的。kafka是不支持主写从读的，这么做的好处是：
> 1) 数据一致性问题。主节点完成写入，副本没来得及同步，客户端这时去读就会拿到旧数据。
> 2) 延迟问题。kafka副本拉去同步主节点的数据时，需要经过网络->主节点内存->主节点磁盘->网络->从节点内存->从节点磁盘。这个过程相对漫长，对延迟敏感的应用不能接受。
