Flink的四个重要的机制分别是：*`Checkpoint`, `State`, `Time`, `Window`。* 分别做一个知识点梳理。

#### 1. Time
时间是Flink实现流批一体的重要特性，主要内容包括：
- Flink时间分类
- WaterMark引入
- 水印运行原理
- 水印API调用
- 旁路输出不丢失
- WaterMark + EventTimeWindow + Allowed Lateness案例。 

**Flink时间分类**
1. EventTime: 事件发生时间，存在于数据本身。
2. ProcessingTime: Flink执行某个operation的时间，会随着系统时钟改变。
3. IngestionTime: 数据从source进入flink程序的时间，一般不用。

随着flink1.11以后的版本，程序不需要手动通过env.setStreamTimeCharacteristic来配置全局的时间属性，而是在使用具体的窗口函数时选择对应的API。

**关于WaterMark**
为什么需要watermark，我们经常需要对某一个时间窗口内的数据进行处理，就会遇到一个场景：假设这个窗口大小是1min，现在要对12：00-12：01的数据进行计算，数据是实时进来的，我们该什么时候进行计算？现实中数据不会完美按照顺序进来的，总会有延迟。我们的程序不可能一直无限等下去的。

这个问题flink是通过watermark机制解决的，就是用来管理，什么时候应该触发我的窗口进行计算。如果没有触发我的watermark，那么数据永远在等待，窗口无法关闭进行计算。

所谓watermark就是一个时间戳，他不会影响原有的事件时间，当我们配置了watermark后，程序会按照watermark来触发窗口计算。

那这个watermark到底长什么样子呢？
> watermark = eventTime - 允许延迟时间。

在实际使用中发现，窗口的分配是按照系统时钟来分配的，假如说，现在有一条数据，时间是2022-01-21 12:34:22，现在定义窗口为60s，watermark为60s，最大延迟为10s，那么实际上，窗口的范围是[2022-01-21 12:34, 2022-01-21 12:35]，加上watermark后，触发窗口计算的时间为：2022-01-21 12:35 + 60 + 60 = 2022-01-21 12:37，也就是说，只有有一条来自2022-01-21 12:37及以后的数据都会触发计算。**这一段话想说的是，窗口是按照系统时钟划分出来的，不要跟EventTime扯上关系，什么时候出发计算，要看watermark，不要管eventTime**

**watermark的API调用及数据延迟处理办法**
通过上面的描述，我们任然无法全面避免数据延迟问题，因为你根本不知道会发生什么情况，导致你的数据延迟几分钟，几小时，甚至几天。那现在假如说有个场景，如果你无法在窗口内消费延迟的数据，那就把这份数据写到另一个地方，其他的程序去专门处理这个延迟数据，那这怎么办？
这就需要Allowed Lateness + OutputTag 组合完成。

Allowed Lateness 解决的是，当窗口出发计算后，又来了一批来自上个窗口的数据，默认不是用这个功能时，新的数据将被丢弃不参与计算。但是，当使用了这个功能后，延迟一段时间达到的数据会再次触发窗口计算，其本质是解决数据乱序达到的。而上次计算的数据实际上会被一个buffer缓存起来，直到超过end-of-window + allowedLateness才会被删除。

那假如，数据还是延迟达到了怎么办？没办法了，直接进入旁路输出通道，尽人事听天命就好了。

总结：
* waterMark解决的是数据延迟问题
* Allowed Lateness解决数据乱序问题
* 旁路输出是最后的兜底。

一个例子，处理数据的窗口操作+水印处理+延迟处理+旁路输出
```java
package basic;

import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.AggregateFunction;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.java.tuple.Tuple3;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.datastream.WindowedStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.util.OutputTag;

import java.time.Duration;
import java.time.Instant;
import java.time.LocalDateTime;
import java.time.ZoneId;
import java.time.format.DateTimeFormatter;
import java.util.ArrayList;

public class WaterExample {
    public static Long timeToLong(String time) {
        DateTimeFormatter ftf = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");
        LocalDateTime parse = LocalDateTime.parse(time, ftf);
        return LocalDateTime.from(parse).atZone(ZoneId.systemDefault()).toInstant().toEpochMilli();
    }
    public static String timeToString(Long time){
        DateTimeFormatter ftf = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");
        return ftf.format(LocalDateTime.ofInstant(Instant.ofEpochMilli(time),ZoneId.systemDefault()));
    }

    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        ArrayList<String> arr = new ArrayList<>();
        arr.add("test1, 2022-01-21 11:04:01,1");
        arr.add("test2, 2022-01-21 11:04:02,1");
        arr.add("test2, 2022-01-21 11:04:03,1");
        arr.add("test1, 2022-01-21 11:04:04,1");
        arr.add("test1, 2022-01-21 11:04:05,1");
//        DataStreamSource<String> stream = env.fromCollection(arr);
        DataStreamSource<String> stream = env.socketTextStream("172.16.7.63", 9999);
        env.setParallelism(1);

        OutputTag<Tuple3<String, Long, Long>> side = new OutputTag<Tuple3<String, Long, Long>>("side") {
        };
        // 封装数据
        SingleOutputStreamOperator<Tuple3<String, Long, Long>> map = stream.map(new MapFunction<String, Tuple3<String, Long, Long>>() {
            @Override
            public Tuple3<String, Long, Long> map(String value) throws Exception {
                String[] splits = value.split(",");
                Tuple3<String, Long, Long> tuple3 = new Tuple3<>();
                tuple3.f0 = splits[0].trim();
                tuple3.f1 = timeToLong(splits[1].trim());
                tuple3.f2 = Long.valueOf(splits[2].trim());
                return tuple3;
            }
        });


        map.map(new MapFunction<Tuple3<String, Long, Long>, String>() {

            @Override
            public String map(Tuple3<String, Long, Long> value) throws Exception {
                return "输入数据：" + timeToString(value.f1);
            }
        }).print();


        // 分配waterMark
        SingleOutputStreamOperator<Tuple3<String, Long, Long>> water =
                map.assignTimestampsAndWatermarks(WatermarkStrategy.
                        <Tuple3<String, Long, Long>>forBoundedOutOfOrderness(Duration.ofSeconds(10)).
                        withTimestampAssigner((event, timestamp) -> event.f1));

        // windows操作
        WindowedStream<Tuple3<String, Long, Long>, String, TimeWindow> pack =
                water.keyBy(line -> line.f0).
                        window(TumblingEventTimeWindows.of(Time.seconds(10)))
                        .allowedLateness(Time.seconds(10))
                        .sideOutputLateData(side);

        // 聚合统计数据
        SingleOutputStreamOperator<Long> agg = pack.aggregate(new AggregateFunction<Tuple3<String, Long, Long>, Long, Long>() {

            @Override
            public Long createAccumulator() {
                return 0L;
            }

            @Override
            public Long getResult(Long accumulator) {
                return accumulator;
            }

            @Override
            public Long merge(Long a, Long b) {
                return null;
            }

            @Override
            public Long add(Tuple3<String, Long, Long> value, Long accumulator) {
                return accumulator + value.f2;
            }
        });
        //正常数据
        agg.print();
        // 延迟数据,把时间打印出来
        agg.getSideOutput(side).map(new MapFunction<Tuple3<String, Long, Long>, String>() {

            @Override
            public String map(Tuple3<String, Long, Long> value) throws Exception {
                return "延迟数据：" + timeToString(value.f1);
            }
        }).print();
        env.execute();
    }
}
/*
// socket连接：
nc -lk 9999 

// 发送数据
test1, 2022-01-21 12:36:22,1
test1, 2022-01-21 12:36:40,1
test1, 2022-01-21 11:37:59,1
test1, 2022-01-21 12:38:00,1
*/
```

#### 2. Window
在flink中，我们对无界的数据流进行处理时，常常需要截取其中一段时间范围内的数据进行计算，如统计最近1分钟内的订单数，最近一小时传感器的最高温度等。而Window就是为了解决此类问题出现的。这与我们处理离线数据很不相同，因为在离线场景下，我们计算时非常明确的知道全体需要参与计算的数据时哪些；但在实时场景下，windows是全新的概念（不要与离线计算的开窗函数混淆，不是一个维度的东西）。使用窗口其实上节已经有一个例子了，使用窗口进行分析，依赖于两个主要的接口：`窗口分配器`与`窗口函数`。

- 窗口分配器。
    flink有下面几种内置的窗口分配器：
    ![images](https://github.com/LadyTao/study-notes/blob/main/bigData/Flink/picture/window-assigners.svg)
    从1.11版本后，窗口分配器就与时间结合在了一起，比如说滚动窗口tumbling，它就有基于event和process的两种实现。
    上面的窗口分2大类：基于时间的(time)与基于数量的(count)。基于count目前没用过。
    各个窗口的特点也如图所示，有不同的特点。
- 窗口函数。
    有三种基本的手段去处理窗口内的数据：
    - 1. 分批处理，调用ProcessWindowFunction，数据将以Iterable的形式传入窗口；
    - 2. 增量处理，调用ReduceFunction 或者AggregateFunction 
    - 3. 组合形式。
    
示例1：
```java
input
    .keyBy(x -> x.key)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .process(new MyWastefulMax());

public static class MyWastefulMax extends ProcessWindowFunction<
        SensorReading,                  // input type
        Tuple3<String, Long, Integer>,  // output type
        String,                         // key type
        TimeWindow> {                   // window type
    
    @Override
    public void process(
            String key,
            Context context, 
            Iterable<SensorReading> events,
            Collector<Tuple3<String, Long, Integer>> out) {

        int max = 0;
        for (SensorReading event : events) {
            max = Math.max(event.value, max);
        }
        // collect返回的数据可以根据需要自己定义，这里只是举例
        out.collect(Tuple3.of(key, context.window().getEnd(), max));
    }}    
```

示例2：
    
```java
DataStream<SensorReading> input = ...

input
    .keyBy(x -> x.key)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .reduce(new MyReducingMax(), new MyWindowFunction());

private static class MyReducingMax implements ReduceFunction<SensorReading> {
    public SensorReading reduce(SensorReading r1, SensorReading r2) {
        return r1.value() > r2.value() ? r1 : r2;
    }}

private static class MyWindowFunction extends ProcessWindowFunction<
    SensorReading, Tuple3<String, Long, SensorReading>, String, TimeWindow> {

    @Override
    public void process(
            String key,
            Context context,
            Iterable<SensorReading> maxReading,
            Collector<Tuple3<String, Long, SensorReading>> out) {

        SensorReading max = maxReading.iterator().next();
        out.collect(Tuple3.of(key, context.window().getEnd(), max));
    }}
```
