flink端到端精准一次消费，需要有三个地方的保证：

![image](https://github.com/LadyTao/study-notes/blob/main/bigData/Flink/picture/%E7%AB%AF%E5%88%B0%E7%AB%AF%E4%B8%80%E8%87%B4.jpg)

前面两个比较好说，因为都是在flink内部。但是在sink阶段要保证精准一次是困难的，因为这已经属于外部系统了，flink本身已经无法控制了。所以端到端一致性不是光靠flink自身就能实现的，外部系统需要一定的机制（事务机制）才行。

我们一般以kafka为例说明。flink实现一致性借助于两端提交协议(2PC)，这个机制通常用来解决分布式系统的事务问题。两阶段提交顾名思义，就是分为两个阶段：
**第一阶段：表决** 协调者发送投票表决，所有的参与者需要返回是否通过的消息；
**第二阶段：提交** 只有当所有参与者确认通过，那么每个参与者本地提交事务，否则取消事务。

![image](https://github.com/LadyTao/study-notes/blob/main/bigData/Flink/picture/%E8%AF%BB%E5%86%99kafka.jpg)

以从kafka读数据写入kafka为例，结合flink流程来讲解：

![image](https://github.com/LadyTao/study-notes/blob/main/bigData/Flink/picture/%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3.jpg)

用自己的话总结一下：
1）Flink首先从source kafka消费一批数据，经过operator处理后需要写入到sink的kafka。此时需要开启一个外部kafka的事务，先将数据写入到kafka，但是数据是未提交状态(uncommited)，这个阶段称为预提交(pre-commit)。
2）预提交阶段sink会接收多个subtask的输出数据，可能会失败。flink可以保障预提交要么全部成功，要么全部失败。且失败会导致flink崩溃，从最新的checkpoint恢复。
3）所有的预提交结束，sink端就会收到完整的barrier数据，将此时状态写入checkpoint 状态后端，并通知JobManager去提交外部事物（此时kafka写数据这个事务只完成了一半）。
4）JobManager收到通知，发出确认信息，表示完成了checkpoint；sink端收到来自JobManager的确认消息，正式提交(commit)数据，完成第二阶段的提交流程。
5）外部系统kafka关闭事务，数据可见，可以正常被消费。

